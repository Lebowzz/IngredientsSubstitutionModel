{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IngredientSubstitutionModel:\n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(2, 3), min_df=2)\n",
    "        self.ingredients_df = None\n",
    "        self.ingredient_vectors = None\n",
    "        self.nutrition_scaler = StandardScaler()\n",
    "        self.cache_file = 'ingredient_model_cache.pkl'\n",
    "        \n",
    "        self.nutrition_columns = [\n",
    "            'CholesterolContent', 'SodiumContent', 'CarbohydrateContent',\n",
    "            'FiberContent', 'SugarContent', 'ProteinContent'\n",
    "        ]\n",
    "        \n",
    "        self.diet_restrictions = {\n",
    "            'vegan': ['chicken', 'beef', 'pork', 'meat', 'breasts', 'duck', 'turkey', 'egg', 'milk', 'cream', 'cheese', 'parmesan', 'butter'],\n",
    "            'vegetarian': ['chicken', 'beef', 'pork', 'breasts', 'duck', 'turkey', 'fish', 'meat'],\n",
    "            'gluten_free': ['wheat', 'flour', 'barley', 'rye', 'oats'],\n",
    "            'dairy_free': ['milk', 'cream', 'cheese', 'butter', 'yogurt', 'parmesan'],\n",
    "            'keto': ['sugar', 'flour', 'corn', 'rice', 'potato']\n",
    "        }\n",
    "        \n",
    "    def load_and_preprocess_data(self, recipe_path, usda_path, foodcom_path, use_cache=True):\n",
    "        \"\"\"\n",
    "        Load and preprocess with nutrition data\n",
    "        \"\"\"\n",
    "        if use_cache and Path(self.cache_file).exists():\n",
    "            with open(self.cache_file, 'rb') as f:\n",
    "                cache_data = pickle.load(f)\n",
    "                self.ingredients_df = cache_data['ingredients_df']\n",
    "                self.ingredient_vectors = cache_data['ingredient_vectors']\n",
    "                self.vectorizer = cache_data['vectorizer']\n",
    "                self.nutrition_scaler = cache_data['nutrition_scaler']\n",
    "            return\n",
    "\n",
    "        # Load datasets with nutrition information\n",
    "        recipe_df = pd.read_csv(recipe_path, usecols=['NER'])\n",
    "        usda_df = pd.read_csv(usda_path, usecols=['ingredients'])\n",
    "        foodcom_df = pd.read_csv(\n",
    "            foodcom_path, \n",
    "            usecols=['RecipeInstructions'] + self.nutrition_columns\n",
    "        )\n",
    "        \n",
    "        # Extract ingredients and nutrition data\n",
    "        ingredients, nutrition_data = self._extract_ingredients_and_nutrition(\n",
    "            recipe_df, usda_df, foodcom_df\n",
    "        )\n",
    "        \n",
    "        # Create main DataFrame\n",
    "        self.ingredients_df = self._create_ingredient_properties(ingredients)\n",
    "        \n",
    "        # Add nutrition data\n",
    "        self.ingredients_df = pd.concat([\n",
    "            self.ingredients_df,\n",
    "            pd.DataFrame(nutrition_data, columns=self.nutrition_columns)\n",
    "        ], axis=1)\n",
    "        \n",
    "        # Scale nutrition data\n",
    "        self.ingredients_df[self.nutrition_columns] = self.nutrition_scaler.fit_transform(\n",
    "            self.ingredients_df[self.nutrition_columns].fillna(0)\n",
    "        )\n",
    "        \n",
    "        # Create TF-IDF vectors\n",
    "        self.ingredient_vectors = self.vectorizer.fit_transform(\n",
    "            self.ingredients_df['ingredient']\n",
    "        )\n",
    "        \n",
    "        # Cache results\n",
    "        if use_cache:\n",
    "            cache_data = {\n",
    "                'ingredients_df': self.ingredients_df,\n",
    "                'ingredient_vectors': self.ingredient_vectors,\n",
    "                'vectorizer': self.vectorizer,\n",
    "                'nutrition_scaler': self.nutrition_scaler\n",
    "            }\n",
    "            with open(self.cache_file, 'wb') as f:\n",
    "                pickle.dump(cache_data, f)\n",
    "    \n",
    "    def _extract_ingredients_and_nutrition(self, recipe_df, usda_df, foodcom_df):\n",
    "        \"\"\"\n",
    "        Extract ingredients and their nutrition data\n",
    "        \"\"\"\n",
    "        ingredients = []\n",
    "        nutrition_data = []\n",
    "        \n",
    "        # Process Food.com data first to get nutrition information\n",
    "        recipe_nutrition = {}\n",
    "        for _, row in foodcom_df.iterrows():\n",
    "            try:\n",
    "                instructions = eval(row['RecipeInstructions'])\n",
    "                for instruction in instructions:\n",
    "                    words = instruction.lower().split()\n",
    "                    for word in words:\n",
    "                        if len(word) > 3:\n",
    "                            cleaned = self._clean_ingredient(word)\n",
    "                            if cleaned:\n",
    "                                recipe_nutrition[cleaned] = {\n",
    "                                    col: row[col] for col in self.nutrition_columns\n",
    "                                }\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        # Process all sources for ingredients\n",
    "        all_ingredients = set()\n",
    "        \n",
    "        # RecipeNLG\n",
    "        for ner_str in recipe_df['NER'].dropna():\n",
    "            try:\n",
    "                ner_ingredients = eval(ner_str)\n",
    "                all_ingredients.update([self._clean_ingredient(i) for i in ner_ingredients])\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        # USDA\n",
    "        for ingredients_str in usda_df['ingredients'].dropna():\n",
    "            ingredients_list = ingredients_str.split(',')\n",
    "            all_ingredients.update([self._clean_ingredient(i) for i in ingredients_list])\n",
    "        \n",
    "        # Create final lists with nutrition data\n",
    "        for ingredient in all_ingredients:\n",
    "            if ingredient:\n",
    "                ingredients.append(ingredient)\n",
    "                if ingredient in recipe_nutrition:\n",
    "                    nutrition_data.append(recipe_nutrition[ingredient])\n",
    "                else:\n",
    "                    # Use average values if nutrition data not available\n",
    "                    avg_nutrition = {col: 0 for col in self.nutrition_columns}\n",
    "                    nutrition_data.append(avg_nutrition)\n",
    "        \n",
    "        return ingredients, nutrition_data\n",
    "    \n",
    "    def _clean_ingredient(self, ingredient):\n",
    "        \"\"\"\n",
    "        Clean ingredient text\n",
    "        \"\"\"\n",
    "        if not isinstance(ingredient, str):\n",
    "            return \"\"\n",
    "        \n",
    "        ingredient = ingredient.lower()\n",
    "        ingredient = re.sub(r'\\([^)]*\\)', '', ingredient)\n",
    "        ingredient = re.sub(r'\\d+(/\\d+)?', '', ingredient)\n",
    "        ingredient = re.sub(r'[^\\w\\s-]', '', ingredient)\n",
    "        return ingredient.strip()\n",
    "    \n",
    "    def _create_ingredient_properties(self, ingredients):\n",
    "        \"\"\"\n",
    "        Create properties DataFrame\n",
    "        \"\"\"\n",
    "        properties = []\n",
    "        for ingredient in ingredients:\n",
    "            prop = {\n",
    "                'ingredient': ingredient,\n",
    "                'is_vegan': not any(r in ingredient for r in self.diet_restrictions['vegan']),\n",
    "                'is_vegetarian': not any(r in ingredient for r in self.diet_restrictions['vegetarian']),\n",
    "                'is_gluten_free': not any(r in ingredient for r in self.diet_restrictions['gluten_free']),\n",
    "                'is_dairy_free': not any(r in ingredient for r in self.diet_restrictions['dairy_free']),\n",
    "                'is_keto': not any(r in ingredient for r in self.diet_restrictions['keto'])\n",
    "            }\n",
    "            properties.append(prop)\n",
    "        return pd.DataFrame(properties)\n",
    "    \n",
    "    def _calculate_similarity_score(self, ingredient_idx, candidate_idx, text_similarity):\n",
    "        \"\"\"\n",
    "        Calculate combined similarity score based on text and nutrition\n",
    "        \"\"\"\n",
    "        # Get nutrition vectors\n",
    "        ingredient_nutrition = self.ingredients_df.iloc[ingredient_idx][self.nutrition_columns].values\n",
    "        candidate_nutrition = self.ingredients_df.iloc[candidate_idx][self.nutrition_columns].values\n",
    "        \n",
    "        # Calculate nutrition similarity\n",
    "        nutrition_similarity = 1 / (1 + np.linalg.norm(ingredient_nutrition - candidate_nutrition))\n",
    "        \n",
    "        # Combined score (70% nutrition, 30% text similarity)\n",
    "        return 0.7 * nutrition_similarity + 0.3 * text_similarity\n",
    "    \n",
    "    def find_substitutes(self, ingredient, diet, n_suggestions=3):\n",
    "        \"\"\"\n",
    "        Find substitutes using combined text and nutrition similarity\n",
    "        \"\"\"\n",
    "        if not isinstance(ingredient, str):\n",
    "            return []\n",
    "            \n",
    "        ingredient = self._clean_ingredient(ingredient)\n",
    "        \n",
    "        if diet not in self.diet_restrictions:\n",
    "            return []\n",
    "            \n",
    "        diet_col = f'is_{diet}'\n",
    "        if diet_col not in self.ingredients_df.columns:\n",
    "            return []\n",
    "            \n",
    "        # Check if substitution needed\n",
    "        ingredient_idx = self.ingredients_df[self.ingredients_df['ingredient'] == ingredient].index\n",
    "        if not ingredient_idx.empty and self.ingredients_df.loc[ingredient_idx[0], diet_col]:\n",
    "            return [\"No substitution needed - ingredient already matches diet\"]\n",
    "            \n",
    "        # Get ingredient vector and calculate text similarities\n",
    "        ingredient_vector = self.vectorizer.transform([ingredient])\n",
    "        text_similarities = cosine_similarity(ingredient_vector, self.ingredient_vectors)[0]\n",
    "        \n",
    "        # Calculate combined scores\n",
    "        scores = []\n",
    "        valid_substitutes = self.ingredients_df[self.ingredients_df[diet_col]].index\n",
    "        \n",
    "        for idx in valid_substitutes:\n",
    "            score = self._calculate_similarity_score(\n",
    "                ingredient_idx[0] if not ingredient_idx.empty else 0,\n",
    "                idx,\n",
    "                text_similarities[idx]\n",
    "            )\n",
    "            scores.append((score, idx))\n",
    "        \n",
    "        # Sort by combined score\n",
    "        scores.sort(reverse=True)\n",
    "        \n",
    "        # Get top substitutes\n",
    "        substitutes = []\n",
    "        for _, idx in scores[:n_suggestions]:\n",
    "            substitutes.append(self.ingredients_df.iloc[idx]['ingredient'])\n",
    "            \n",
    "        return substitutes if substitutes else [\"No suitable substitutes found\"]\n",
    "    \n",
    "    def process_recipe(self, ingredients_list, diet):\n",
    "        \"\"\"\n",
    "        Process recipe ingredients\n",
    "        \"\"\"\n",
    "        return {\n",
    "            ingredient: subs \n",
    "            for ingredient in ingredients_list\n",
    "            if (subs := self.find_substitutes(ingredient, diet)) and \n",
    "               subs[0] != \"No substitution needed - ingredient already matches diet\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize model\n",
    "    model = IngredientSubstitutionModel()\n",
    "    \n",
    "    # Load data with caching\n",
    "    model.load_and_preprocess_data(\n",
    "        'RecipeNLG_full_dataset_small.csv',\n",
    "        'branded_food_small.csv',\n",
    "        'recipes_small.csv',\n",
    "        use_cache=True\n",
    "    )\n",
    "    \n",
    "    # Test recipe\n",
    "    recipe_ingredients = [\n",
    "        \"chicken breasts\",\n",
    "        \"cream of mushroom\",\n",
    "        \"garlic\",\n",
    "        \"butter\",\n",
    "        \"parmesan cheese\"\n",
    "    ]\n",
    "    \n",
    "    # Get substitutions\n",
    "    substitutions = model.process_recipe(recipe_ingredients, 'keto')\n",
    "    \n",
    "    # Print resultsx\n",
    "    print(\"\\nRecipe Substitutions:\")\n",
    "    for ingredient, subs in substitutions.items():\n",
    "        print(f\"\\n{ingredient} can be substituted with:\")\n",
    "        for sub in subs:\n",
    "            print(f\"- {sub}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IngredientSubstitutionModel:\n",
    "    def __init__(self):\n",
    "        self.bert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        self.ingredient_embeddings = None\n",
    "        self.ingredients_df = None\n",
    "        self.diet_restrictions = {\n",
    "            'vegan': ['chicken', 'beef', 'pork', 'meat', 'egg', 'milk', 'cream', 'cheese', 'butter', 'honey'],\n",
    "            'vegetarian': ['chicken', 'beef', 'pork', 'fish', 'meat'],\n",
    "            'gluten_free': ['wheat', 'flour', 'barley', 'rye', 'oats'],\n",
    "            'dairy_free': ['milk', 'cream', 'cheese', 'butter', 'yogurt', 'whey'],\n",
    "            'keto': ['sugar', 'flour', 'corn', 'rice', 'potato']\n",
    "        }\n",
    "        \n",
    "    def load_and_preprocess_data(self, recipe_path, usda_path, foodcom_path):\n",
    "        \"\"\"\n",
    "        Load and preprocess the datasets based on their specific structures\n",
    "        \"\"\"\n",
    "        # Load datasets\n",
    "        recipe_df = pd.read_csv(recipe_path)\n",
    "        usda_df = pd.read_csv(usda_path)\n",
    "        foodcom_df = pd.read_csv(foodcom_path)\n",
    "        \n",
    "        # Extract ingredients from each dataset\n",
    "        ingredients = self._extract_unique_ingredients(recipe_df, usda_df, foodcom_df)\n",
    "        \n",
    "        # Create ingredient properties DataFrame\n",
    "        self.ingredients_df = self._create_ingredient_properties(ingredients)\n",
    "        \n",
    "        # Generate embeddings\n",
    "        self.ingredient_embeddings = self._generate_embeddings(\n",
    "            self.ingredients_df['ingredient'].tolist()\n",
    "        )\n",
    "        \n",
    "    def _extract_unique_ingredients(self, recipe_df, usda_df, foodcom_df):\n",
    "        \"\"\"\n",
    "        Extract ingredients considering the specific structure of each dataset\n",
    "        \"\"\"\n",
    "        all_ingredients = set()\n",
    "        \n",
    "        # Extract from RecipeNLG using NER field\n",
    "        for ner_list in recipe_df['NER'].dropna():\n",
    "            try:\n",
    "                ingredients = ast.literal_eval(ner_list)\n",
    "                all_ingredients.update(ingredients)\n",
    "            except (ValueError, SyntaxError):\n",
    "                continue\n",
    "                \n",
    "        # Extract from USDA branded food\n",
    "        for ingredients_str in usda_df['ingredients'].dropna():\n",
    "            # Split USDA ingredients which are comma-separated\n",
    "            ingredients = [i.strip() for i in ingredients_str.split(',')]\n",
    "            all_ingredients.update(ingredients)\n",
    "            \n",
    "        # Extract from Food.com\n",
    "        for recipe_instructions in foodcom_df['RecipeInstructions'].dropna():\n",
    "            try:\n",
    "                instructions = ast.literal_eval(recipe_instructions)\n",
    "                # Extract ingredients mentioned in instructions\n",
    "                for instruction in instructions:\n",
    "                    words = instruction.lower().split()\n",
    "                    # Add potential ingredients (words longer than 3 characters)\n",
    "                    all_ingredients.update([w for w in words if len(w) > 3])\n",
    "            except (ValueError, SyntaxError):\n",
    "                continue\n",
    "        \n",
    "        # Clean ingredients\n",
    "        cleaned_ingredients = set()\n",
    "        for ingredient in all_ingredients:\n",
    "            cleaned = self._clean_ingredient(ingredient)\n",
    "            if cleaned and len(cleaned) > 2:  # Filter out very short ingredients\n",
    "                cleaned_ingredients.add(cleaned)\n",
    "                \n",
    "        return list(cleaned_ingredients)\n",
    "    \n",
    "    def _clean_ingredient(self, ingredient):\n",
    "        \"\"\"\n",
    "        Clean ingredient text with improved handling for our specific datasets\n",
    "        \"\"\"\n",
    "        if not isinstance(ingredient, str):\n",
    "            return \"\"\n",
    "            \n",
    "        ingredient = ingredient.lower()\n",
    "        \n",
    "        # Remove common measurement words\n",
    "        measurements = ['cup', 'tablespoon', 'teaspoon', 'ounce', 'pound', 'gram', \n",
    "                      'kg', 'ml', 'g', 'oz', 'lb', 'tsp', 'tbsp']\n",
    "        for measurement in measurements:\n",
    "            ingredient = re.sub(fr'\\d+\\s*{measurement}s?\\b', '', ingredient)\n",
    "            \n",
    "        # Remove parenthetical content\n",
    "        ingredient = re.sub(r'\\([^)]*\\)', '', ingredient)\n",
    "        \n",
    "        # Remove numbers and fractions\n",
    "        ingredient = re.sub(r'\\d+(/\\d+)?', '', ingredient)\n",
    "        \n",
    "        # Remove special characters but keep hyphens\n",
    "        ingredient = re.sub(r'[^\\w\\s-]', '', ingredient)\n",
    "        \n",
    "        # Remove common preparation instructions\n",
    "        prep_words = ['chopped', 'diced', 'minced', 'sliced', 'grated', 'crushed']\n",
    "        for word in prep_words:\n",
    "            ingredient = ingredient.replace(word, '')\n",
    "            \n",
    "        # Clean up extra spaces and hyphens\n",
    "        ingredient = re.sub(r'\\s+', ' ', ingredient)\n",
    "        ingredient = ingredient.strip('- ')\n",
    "        \n",
    "        return ingredient\n",
    "    \n",
    "    def _create_ingredient_properties(self, ingredients):\n",
    "        \"\"\"\n",
    "        Create DataFrame with ingredient properties and nutritional information\n",
    "        \"\"\"\n",
    "        properties = []\n",
    "        for ingredient in ingredients:\n",
    "            prop = {\n",
    "                'ingredient': ingredient,\n",
    "                'is_vegan': not any(r in ingredient for r in self.diet_restrictions['vegan']),\n",
    "                'is_vegetarian': not any(r in ingredient for r in self.diet_restrictions['vegetarian']),\n",
    "                'is_gluten_free': not any(r in ingredient for r in self.diet_restrictions['gluten_free']),\n",
    "                'is_dairy_free': not any(r in ingredient for r in self.diet_restrictions['dairy_free']),\n",
    "                'is_keto': not any(r in ingredient for r in self.diet_restrictions['keto'])\n",
    "            }\n",
    "            properties.append(prop)\n",
    "        return pd.DataFrame(properties)\n",
    "    \n",
    "    def _generate_embeddings(self, ingredients):\n",
    "        \"\"\"\n",
    "        Generate embeddings for ingredients using BERT\n",
    "        \"\"\"\n",
    "        return self.bert_model.encode(ingredients, show_progress_bar=True)\n",
    "    \n",
    "    def find_substitutes(self, ingredient, diet, n_suggestions=3):\n",
    "        \"\"\"\n",
    "        Find substitutes for an ingredient based on diet\n",
    "        \"\"\"\n",
    "        if not isinstance(ingredient, str):\n",
    "            return []\n",
    "            \n",
    "        ingredient = self._clean_ingredient(ingredient)\n",
    "        \n",
    "        if diet not in self.diet_restrictions:\n",
    "            return []\n",
    "            \n",
    "        diet_col = f'is_{diet}'\n",
    "        if diet_col not in self.ingredients_df.columns:\n",
    "            return []\n",
    "            \n",
    "        ingredient_idx = self.ingredients_df[self.ingredients_df['ingredient'] == ingredient].index\n",
    "        if not ingredient_idx.empty and self.ingredients_df.loc[ingredient_idx[0], diet_col]:\n",
    "            return [\"No substitution needed - ingredient already matches diet\"]\n",
    "            \n",
    "        ingredient_embedding = self.bert_model.encode([ingredient])[0]\n",
    "        \n",
    "        similarities = cosine_similarity(\n",
    "            [ingredient_embedding], \n",
    "            self.ingredient_embeddings\n",
    "        )[0]\n",
    "        \n",
    "        valid_substitutes = self.ingredients_df[self.ingredients_df[diet_col]].index\n",
    "        similar_indices = similarities.argsort()[::-1]\n",
    "        \n",
    "        substitutes = []\n",
    "        for idx in similar_indices:\n",
    "            if idx in valid_substitutes and len(substitutes) < n_suggestions:\n",
    "                substitutes.append(self.ingredients_df.iloc[idx]['ingredient'])\n",
    "                \n",
    "        return substitutes if substitutes else [\"No suitable substitutes found\"]\n",
    "    \n",
    "    def process_recipe(self, ingredients_list, diet):\n",
    "        \"\"\"\n",
    "        Process a list of ingredients and find substitutes where needed\n",
    "        \"\"\"\n",
    "        substitutions = {}\n",
    "        for ingredient in ingredients_list:\n",
    "            subs = self.find_substitutes(ingredient, diet)\n",
    "            if subs and subs[0] != \"No substitution needed - ingredient already matches diet\":\n",
    "                substitutions[ingredient] = subs\n",
    "        return substitutions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
